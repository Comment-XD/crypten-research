{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comet/anaconda3/envs/research_py/lib/python3.9/site-packages/crypten/__init__.py:64: RuntimeWarning: CrypTen is already initialized.\n",
      "  warnings.warn(\"CrypTen is already initialized.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import crypten\n",
    "import crypten.nn as cnn\n",
    "import crypten.mpc as mpc\n",
    "import crypten.communicator as comm\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision.models.resnet import *\n",
    "\n",
    "crypten.init()\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "x_enc = crypten.cryptensor(x)\n",
    "\n",
    "\n",
    "y = torch.tensor([3.0, 4.0, 5.0])\n",
    "y_enc = crypten.cryptensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# has to be encoding first then the non-encoded value\n",
    "\n",
    "z = y_enc + x\n",
    "z_enc = x_enc + y_enc\n",
    "\n",
    "crypten.print(z.get_plain_text())\n",
    "crypten.print(z_enc.get_plain_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 100\n",
    "num_train_examples = 1000\n",
    "num_test_examples = 100\n",
    "epochs = 100\n",
    "lr = 1e-4\n",
    "\n",
    "features = torch.randn(num_features, num_train_examples)\n",
    "w_true = torch.randn(1, num_features)\n",
    "b_true = torch.rand(1)\n",
    "\n",
    "labels = w_true.matmul(features).add(b_true).sign()\n",
    "test_features = torch.rand(num_features, num_test_examples)\n",
    "test_labels = w_true.matmul(test_features).add(b_true).sign()\n",
    "\n",
    "# gets the first 50 features \n",
    "features[:50].size()\n",
    "\n",
    "#gets the last 50 features\n",
    "features[50:].size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets load in the MNIST Digit Dataset, and Iris Dataset\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "iris_dataset = datasets.load_iris()\n",
    "iris_dataset.keys()\n",
    "\n",
    "\n",
    "iris_dataset[\"target\"] = iris_dataset[\"target\"][:, np.newaxis]\n",
    "iris_dataset[\"target\"] = iris_dataset[\"target\"].astype(np.float64)\n",
    "iris_data = np.concatenate([iris_dataset[\"data\"], iris_dataset[\"target\"]], axis=-1)\n",
    "iris_dataset[\"feature_names\"].extend([\"label\"])\n",
    "\n",
    "iris_cols = iris_dataset[\"feature_names\"]\n",
    "iris_df = pd.DataFrame(iris_data, columns=iris_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df[\"label\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = iris_df.drop(columns=[\"label\"])\n",
    "y = iris_df[[\"label\"]]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_labels = torch.eye(3)\n",
    "print(one_hot_labels)\n",
    "\n",
    "one_hot_labels[y_train.values.squeeze()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        super().__init__()\n",
    "        self.features = torch.tensor(features.values)\n",
    "        \n",
    "        one_hot_labels = torch.eye(3)\n",
    "        self.labels = one_hot_labels[labels.values.squeeze()]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "train_dataset = Dataset(X_train, y_train)\n",
    "test_dataset = Dataset(X_test, y_test)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=10, num_workers=1, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=10, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicLinearModel(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.Linear(in_features, hidden_features),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_features, hidden_features),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.l2 = nn.Sequential(\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(hidden_features, out_features),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.l2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, \n",
    "                 input_shape, \n",
    "                 model, \n",
    "                 train_dataloader, \n",
    "                 test_dataloader, \n",
    "                 loss_function) -> None:\n",
    "        \n",
    "        model_plaintext = model\n",
    "        dummy_input = torch.empty(*input_shape)\n",
    "        model = crypten.nn.from_pytorch(model_plaintext, dummy_input)\n",
    "\n",
    "        self.model = model\n",
    "        self.model.encrypt()\n",
    "\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.test_dataloader = test_dataloader\n",
    "        self.loss_function = loss_function\n",
    "        self.divider = \"-\" * 4\n",
    "    \n",
    "\n",
    "    def train_one_epoch(self, lr:int) -> None:\n",
    "\n",
    "        # Puts the model into train mode\n",
    "        self.model.train()\n",
    "\n",
    "        print(\"\\n\" + self.divider + \"Train\" + self.divider)\n",
    "        train_loss = 0\n",
    "\n",
    "        for _, (X, y) in enumerate(self.train_dataloader):\n",
    "                \n",
    "            encryped_X = crypten.cryptensor(X)\n",
    "            encryped_y = crypten.cryptensor(y, requires_grad=True)\n",
    "\n",
    "            output = self.model(encryped_X)\n",
    "            loss = self.loss_function(output, encryped_y)\n",
    "\n",
    "            self.model.zero_grad()\n",
    "            loss.backward()\n",
    "            self.model.update_parameters(lr)\n",
    "\n",
    "            train_loss += loss.get_plain_text()\n",
    "        \n",
    "        print(f\"Train Batch Loss: {train_loss.item() / len(self.train_dataloader) : .4f}\")\n",
    "    \n",
    "    def validate(self) -> None:\n",
    "        self.model.eval()\n",
    "\n",
    "        print(\"\\n\" + self.divider + \"Test\" + self.divider)\n",
    "        test_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for _, (X, y) in enumerate(self.test_dataloader): \n",
    "                encryped_X = crypten.cryptensor(X)\n",
    "                encryped_y = crypten.cryptensor(y, requires_grad=False)\n",
    "\n",
    "                output = self.model(encryped_X)\n",
    "                loss = self.loss_function(output, encryped_y)\n",
    "\n",
    "                test_loss += loss.get_plain_text()\n",
    "        \n",
    "        print(f\"Test Batch Loss: {test_loss.item() / len(self.test_dataloader) : .4f}\\n\")\n",
    "    \n",
    "\n",
    "    def run(self, lr, epochs):\n",
    "        for i in range(epochs):\n",
    "            print(f\"Current Epoch: {i + 1}\\n\" + \"=\" * 16)\n",
    "            self.train_one_epoch(lr)\n",
    "            self.validate()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = BasicLinearModel(in_features=4,\n",
    "                                hidden_features=10, \n",
    "                                out_features=3)\n",
    "\n",
    "cross_entropy_loss_fn = crypten.nn.CrossEntropyLoss()\n",
    "\n",
    "trainer = Trainer(model=linear_model,\n",
    "                  input_shape=(1, 4),\n",
    "                  train_dataloader=train_dataloader,\n",
    "                  test_dataloader=test_dataloader,\n",
    "                  loss_function=cross_entropy_loss_fn)\n",
    "\n",
    "trainer.run(lr=0.1, \n",
    "              epochs=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import crypten.mpc as mpc\n",
    "import crypten.communicator as comm\n",
    "\n",
    "private_model = crypten.nn.from_pytorch(linear_model, torch.empty(1, 4))\n",
    "\n",
    "@mpc.run_multiprocess(world_size=2)\n",
    "def inference():\n",
    "    \n",
    "    private_model.encrypt()\n",
    "    rank = comm.get().get_rank()\n",
    "    \n",
    "    print(f\"\\nRank {rank}:\\n {private_model.state_dict()}\")\n",
    "\n",
    "inference()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.resnet import resnet18\n",
    "import torch\n",
    "\n",
    "import crypten\n",
    "import crypten.mpc as mpc\n",
    "\n",
    "crypten.init()\n",
    "\n",
    "\n",
    "model = resnet18()\n",
    "dummmy_input = torch.empty(64, 3, 28, 28)\n",
    "\n",
    "crypten.nn.from_pytorch(model, dummmy_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet(nn.Sequential):\n",
    "    \"\"\"\n",
    "    Adaptation of LeNet that uses ReLU activations\n",
    "    \"\"\"\n",
    "\n",
    "    # network architecture:\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "\n",
    "        # Batchnorm results in \n",
    "        self.batchnorm1 = crypten.nn.BatchNorm2d(16)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.batchnorm1(self.conv2(x))))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        # nn.AdaptiveAvgPool2d((1,1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import crypten.nn as cnn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CryptenLeNet(crypten.nn.Module):\n",
    "    \"\"\"\n",
    "    Adaptation of LeNet that uses ReLU activations\n",
    "    \"\"\"\n",
    "\n",
    "    # network architecture:\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = cnn.Conv2d(3, 6, 5)\n",
    "        self.pool = cnn.MaxPool2d(2, 2)\n",
    "        self.conv2 = cnn.Conv2d(6, 16, 5)\n",
    "\n",
    "        # Batchnorm results in \n",
    "        self.batchnorm1 = cnn.BatchNorm2d(16)\n",
    "        self.fc1 = cnn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = cnn.Linear(120, 84)\n",
    "        self.fc3 = cnn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.batchnorm1(self.conv2(x))))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = crypten.nn.Rel.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        # nn.AdaptiveAvgPool2d((1,1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-10:\n",
      "Process Process-9:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/comet/anaconda3/envs/research_py/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/comet/anaconda3/envs/research_py/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/comet/anaconda3/envs/research_py/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/comet/anaconda3/envs/research_py/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/comet/anaconda3/envs/research_py/lib/python3.9/site-packages/crypten/mpc/context.py\", line 30, in _launch\n",
      "    return_value = func(*func_args, **func_kwargs)\n",
      "  File \"/home/comet/anaconda3/envs/research_py/lib/python3.9/site-packages/crypten/mpc/context.py\", line 30, in _launch\n",
      "    return_value = func(*func_args, **func_kwargs)\n",
      "  File \"/tmp/ipykernel_2823/3109621198.py\", line 15, in inference\n",
      "    print(f\"\\nRank {rank}:\\n {leNet(crypted_data)}\")\n",
      "  File \"/tmp/ipykernel_2823/3109621198.py\", line 15, in inference\n",
      "    print(f\"\\nRank {rank}:\\n {leNet(crypted_data)}\")\n",
      "  File \"/home/comet/anaconda3/envs/research_py/lib/python3.9/site-packages/crypten/nn/module.py\", line 50, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/home/comet/anaconda3/envs/research_py/lib/python3.9/site-packages/crypten/nn/module.py\", line 532, in forward_function\n",
      "    return object.__getattribute__(self, name)(*tuple(args), **kwargs)\n",
      "  File \"/tmp/ipykernel_2823/1809046924.py\", line 23, in forward\n",
      "    x = self.pool(F.relu(self.conv1(x)))\n",
      "  File \"/home/comet/anaconda3/envs/research_py/lib/python3.9/site-packages/torch/nn/functional.py\", line 1700, in relu\n",
      "    return handle_torch_function(relu, (input,), input, inplace=inplace)\n",
      "  File \"/home/comet/anaconda3/envs/research_py/lib/python3.9/site-packages/crypten/nn/module.py\", line 50, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/home/comet/anaconda3/envs/research_py/lib/python3.9/site-packages/torch/overrides.py\", line 1739, in handle_torch_function\n",
      "    result = torch_func_method(public_api, types, args, kwargs)\n",
      "  File \"/home/comet/anaconda3/envs/research_py/lib/python3.9/site-packages/crypten/cryptensor.py\", line 300, in __torch_function__\n",
      "    raise NotImplementedError(\n",
      "  File \"/home/comet/anaconda3/envs/research_py/lib/python3.9/site-packages/crypten/nn/module.py\", line 532, in forward_function\n",
      "    return object.__getattribute__(self, name)(*tuple(args), **kwargs)\n",
      "  File \"/tmp/ipykernel_2823/1809046924.py\", line 23, in forward\n",
      "    x = self.pool(F.relu(self.conv1(x)))\n",
      "  File \"/home/comet/anaconda3/envs/research_py/lib/python3.9/site-packages/torch/nn/functional.py\", line 1700, in relu\n",
      "    return handle_torch_function(relu, (input,), input, inplace=inplace)\n",
      "NotImplementedError: CrypTen does not support torch function <function relu at 0x7896c0d4ddc0>.\n",
      "  File \"/home/comet/anaconda3/envs/research_py/lib/python3.9/site-packages/torch/overrides.py\", line 1739, in handle_torch_function\n",
      "    result = torch_func_method(public_api, types, args, kwargs)\n",
      "  File \"/home/comet/anaconda3/envs/research_py/lib/python3.9/site-packages/crypten/cryptensor.py\", line 300, in __torch_function__\n",
      "    raise NotImplementedError(\n",
      "NotImplementedError: CrypTen does not support torch function <function relu at 0x7896c0d4ddc0>.\n",
      "[rank0]:[W1111 14:12:30.021429158 NNPACK.cpp:61] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[rank1]:[W1111 14:12:30.021697493 NNPACK.cpp:61] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "ERROR:root:One of the parties failed. Check past logs\n"
     ]
    }
   ],
   "source": [
    "import crypten.mpc as mpc\n",
    "\n",
    "leNet = CryptenLeNet()\n",
    "\n",
    "\n",
    "@mpc.run_multiprocess(world_size=2)\n",
    "def inference():\n",
    "\n",
    "    crypted_data = crypten.rand(1, 3, 32, 32)\n",
    "    \n",
    "    leNet.encrypt()\n",
    "    rank = comm.get().get_rank()\n",
    "    \n",
    "    print(f\"\\nRank {rank}:\\n {leNet(crypted_data)}\")\n",
    "\n",
    "inference()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CryptenLeNet()\n",
    "dummmy_input = torch.empty(1, 3, 32, 32)\n",
    "model.encrypt()\n",
    "\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "model = resnet18().to(\"cpu\")\n",
    "dummy_input = torch.empty(64, 3, 32, 32)\n",
    "# model = crypten.load_from_party(preloaded=model, model_class=torchvision.models.resnet.ResNet)\n",
    "model.eval()\n",
    "\n",
    "crypten.common.serial.register_safe_class(torchvision.models.resnet.ResNet)\n",
    "\n",
    "model = cnn.from_pytorch(model, dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypten.common.serial.register_safe_class(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18().to(\"cpu\")\n",
    "dummmy_input = torch.empty(1, 3, 28, 28)\n",
    "\n",
    "\n",
    "model = crypten.load_from_party(preloaded=model, model_class=resnet18())\n",
    "crypten.nn.from_pytorch(model, dummmy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoopContextManager:\n",
    "    \"\"\"Context manager that does nothing.\"\"\"\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        pass\n",
    "\n",
    "context_manager = NoopContextManager()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "model_name=\"resnet18\"\n",
    "dummmy_input = torch.empty(1, 3, 224, 224)\n",
    "\n",
    "with context_manager:\n",
    "        model = getattr(models, model_name)(pretrained=True)\n",
    "        model.eval()\n",
    "        # dataset = datasets.ImageNet(imagenet_folder, split=\"val\", download=download)\n",
    "\n",
    "\n",
    "encrypted_model = crypten.nn.from_pytorch(model, dummy_input=dummy_input)\n",
    "encrypted_model.encrypt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crypted RELU:  0.250626  \n",
      "Crypted RELU:  0.281813  RELU:  0.000209  \n",
      "\n",
      "RELU:  0.000290  \n",
      "\n",
      "Rank 1:\n",
      " Encrypted Output: MPCTensor(\n",
      "\t_tensor=tensor([4238793319733541260, -496873920919160655, 4651535131736646381])\n",
      "\tplain_text=HIDDEN\n",
      "\tptype=ptype.arithmetic\n",
      ") | Real Output: tensor([0., 1., 2.])\n",
      "Rank 0:\n",
      " Encrypted Output: MPCTensor(\n",
      "\t_tensor=tensor([-4238793319733541260,   496873920919226191, -4651535131736515309])\n",
      "\tplain_text=HIDDEN\n",
      "\tptype=ptype.arithmetic\n",
      ") | Real Output: tensor([0., 1., 2.])\n",
      "\n",
      "\n",
      "Rank 0:\n",
      " Output: tensor([0, 1, 2]) | Output: tensor([0, 1, 2])\n",
      "\n",
      "Rank 1:\n",
      " Output: tensor([0, 1, 2]) | Output: tensor([0, 1, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import crypten\n",
    "import crypten.mpc as mpc\n",
    "import crypten.communicator as comm\n",
    "\n",
    "import time \n",
    "\n",
    "crypten.init()\n",
    "\n",
    "\n",
    "@mpc.run_multiprocess(world_size=2)\n",
    "def inference():\n",
    "    \n",
    "    data = torch.tensor([-1,1,2])\n",
    "    encrypted_data = crypten.cryptensor(data)\n",
    "\n",
    "    regular_relu = nn.ReLU()\n",
    "\n",
    "    crypted_relu = crypten.nn.ReLU()\n",
    "    crypted_relu.encrypt()\n",
    "\n",
    "    rank = comm.get().get_rank()\n",
    "    start = time.time()\n",
    "    encrypted_output = crypted_relu(encrypted_data)\n",
    "    print(f\"Crypted RELU: {time.time() - start : 4f}  \")    \n",
    "    \n",
    "    start = time.time()\n",
    "    output = regular_relu(data)\n",
    "\n",
    "    print(f\"RELU: {time.time() - start : 4f}  \")\n",
    "    print(f\"\\nRank {rank}:\\n Encrypted Output: {encrypted_output} | Real Output: {encrypted_output.get_plain_text()}\")\n",
    "    print(f\"\\nRank {rank}:\\n Output: {output} | Output: {output}\")\n",
    "    \n",
    "\n",
    "inference()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
